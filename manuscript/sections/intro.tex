\section{Introduction}
\label{sec:intro}
On March 2nd, 2016, the Pentagon announced the launch of its first {\it bug bounty} program \cite{Pentagon}. From now on, the most secured organization in the United States will incentivize hackers to break into its systems and report found vulnerabilities for a reward. Although bug bounty programs have mushroomed in the last few years, this audacious announcement by the most paranoid governmental organization in the United States may set a precedent, if not a standard, for the future of cybersecurity practice. Software security has long been recognized as a ``hard" computational problem \cite{adams1984textordfeminineoptimizing}, at which human intelligence might be a better resource, or at least a complementary one. However, given today's complexity of computer systems, individual human intelligence seems to have become insufficient, and organizations interested in drastically increasing their security, nowadays attempt to tap the wisdom of crowds \cite{surowiecki2005wisdom}, just like other disciplines have found ways to mobilize people at scale for their hard problems, such as sorting galaxies \cite{smith2013introduction}, folding proteins in biology \cite{khatib2011algorithm}, recognizing words from low quality book scans \cite{von2003captcha} or to address outstanding mathematics problems \cite{gowers2009massively,cranshaw2011polymath}.\\ 

All the above examples involve various aspects of human intelligence ranging from pattern recognition (Captcha) to highest abstraction levels (mathematical conjectures). It is not clear what kind of intelligence is required to find bugs and vulnerabilities in software, but it generally requires a high level of programming proficiency coupled a {\it hacking} sense of how to piece things apart to better understand them. In a nutshell, searching for complicated  bugs and vulnerabilities may be a hard and time-consuming task, which is generally not, or at least no longer, considered as a leisure that hackers perform for hedonic pleasure or the good.\\

Therefore, nowadays some (monetary) incentives must be set to get security researchers invest some of their time hunting bugs. Offering rewards for vulnerabilities has been a long endeavor over the last decade \cite{bohme2006comparison}, with many more or less successful attempts to set incentives right \cite{finifter2013empirical,zhao2014exploratory,zhao2015empirical}. HackerOne, the first online service dedicated to help organizations set up and manage their own bug bounty program, has paved the way to the deployment at scale of bounty programs. Nevertheless, in this pioneering era of bug bounty hunting, it remains unclear how current mechanism designs and incentives structures influence the long-term success of bounty programs, and how they may evolve in the foreseeable future, following enhanced understanding of bug discovery mechanisms on the one hand \cite{zhao2016empirical}, and on the other hand, from better characterization of the utility functions of respectively organizations operating a bug bounty program and security researchers.\\

Here, we investigate a public data set of 35 public bug bounty programs from the HackerOne website. We find that as more vulnerabilities get discovered within a bounty program, security researchers face an increasingly difficult environment in which the probability of find a bug decreases fast, while reward increases. This phenomenon is reminiscent of the St-Petersburg paradox famous in behavioral economics, in which people have increasingly hard time to make a rational choice. For this reason, as well as because the probability of find a bug decreases faster compared to the payoff increase, security researchers are incentivized to consistently switch to newly launched research programs, at the expense of older programs (the switching phenomenon has already been found in \cite{zhao2015empirical}). \\

This article is organized as follows. Related research is presented in Section \ref{sec:related}. Important features of the data set used here is detailed in Section \ref{sec:data}. We then introduce the main mechanism driving vulnerability discovery in Section \ref{sec:method}. Results are presented and discussed in respectively Sections \ref{sec:results} and \ref{sec:discussion}. We finally in conclude in Section \ref{sec:conclusion}.