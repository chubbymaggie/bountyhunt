\section{Related work}
\label{sec:related}
Achieving software reliability has concerned engineers for at least four decades \cite{littlewood1973bayesian,adams1984textordfeminineoptimizing,littlewood1989predicting}. Early empirical work on software bug discovery dates back to the time of UNIX systems \cite{miller1990empirical}, and over years, numbers of models for discovering vulnerabilities have been developed (see \cite{yamaguchi2014modeling,zhao2016empirical} for some of the most contemporary approaches to date). However, as early as in 1989, it was recognized the the time to achieve a given level of reliability is inversely proportional to desired frequency level (e.g., to achieve a $10^{-9}$ probability of failure, it takes $10^{9}$ time units) \cite{adams1984textordfeminineoptimizing}. Actually, the random variable $P(T > t) = 1/t$ corresponds to the Zipf's law, which diverges as the random variable sample increases (i.e., no statistical moment is defined) \cite{maillart2008empirical,saichev2009theory}, and thus, it was rightly concluded that there would be software vulnerabilities as long as long enough resources and time could be provided to find them. This problem can also be seen from an entropy maximization perspective, which is good for evolution (e.g., in biology) but detrimental in software engineering \cite{brady1999murphy}. \\

To date, no systematic algorithm approach has been found to get rid of bugs at a speed that would allow following the general pace of software evolution and expansion. Thus human intelligence is still considered as one of the most efficient ways to find bugs, and most importantly to uncover software vulnerabilities. Management techniques and governance approached have been developed to help software developers and security researchers in their review tasks, starting with {\it pair programming} \cite{hulkko2005multiple}. To protect against cyber-criminals, it is also fashionable to hire {\it ethical hackers}, who use the mindset of potential attackers to test the security of computer systems \cite{smith2002ethical,saleem2006ethical,bishop2007penetration}. Inherited from the open source mindset, the full-disclosure policy has been hotly debated as promoting a safer Internet \cite{arora2008optimal}, although in practice it seems that public disclosure has increasingly become a dominant standard to get people and organizations informed as fast as possible about software vulnerabilities.\\

In most of these successful human-driven approaches, there is knowledge-sharing component, may it be between two programmers sitting together in front of a screen, ethical hackers being hired to discover and explore the weaknesses of a computer system, or the broader community being exposed to open source code and publicly disclosed software vulnerabilities. Thus, Eric Raymond's famous quote ``Given enough eyeballs, all bugs shallow" \cite{raymond1999cathedral}, tends to hold, even though in practice things are often slightly more complicated \cite{hafiz2015game}.\\

Recognizing the need of human intelligence at scale for tackling security bugs, researchers have considered early on the importance of trading bugs and vulnerability as a valuable and often hardly earned, knowledge. {\it Vulnerability markets} have thus emerged as a way to ensure appropriate incentives for knowledge transfer from security researchers to software and Internet organizations \cite{camp2004pricing}, and in particular, to jointly harness the wisdom of crowds and reveal the security level of organizations through a competitive incentive scheme \cite{schechter2002buy}. The efficiency of vulnerability markets has however been nevertheless questioned on both theoretical \cite{kannan2005market,mckinney2007vulnerability} and empirical grounds \cite{ransbotham2008markets,algarni2014software}.\\

Early on and building on previous work by Schechter \cite{schechter2002buy}, Andy Ozment \cite{ozment2004bug} recognized that in theory most efficient mechanism designs shall not be markets {\it per se}, but rather auction systems \cite{milgrom1982theory}. In a nutshell, the proposed (monopsonistic) auction mechanism implies an initial $R(t=t_0) = R_0$, which increases linearly with time.  If a vulnerability is reported more than once, only the first reporter receives the reward. Therefore, security researchers have an incentive to submit a vulnerability early (before other researchers might submit the same vulnerability), but not too early, so that can maximize their payoff $R(t) = R_0 + \epsilon t$ with $r$ the linear growth factor, which is also supposed to compensate for the increasing difficulty of finding each new bug. But setting the right $\{R_0,\epsilon \}$ is not trivial, because it must account number of uncertainties \cite{pandey2014assessment}, such as work needed, or effective competition (i.e., the number of researchers enrolled in the bug program).\\

Regardless of theoretical considerations (or perhaps by integrating them), vulnerability reward programs have emerged, first launched by specific software companies for their own needs and with rather heterogeneous incentive schemes\cite{finifter2013empirical}, including with no monetary reward \cite{zhao2014exploratory}, and followed by dedicated platforms comparable to trusted third parties in charge of clearing transactions between bug bounty programs launched by organizations and security researchers. These platforms also assist organizations in the design and deployment of their own program. The currently leading platform is HackerOne.\footnote{HackerOne, \url{https://hackerone.com/} (last access March, 4th 2016).} HackerOne runs 35 public programs, for organizations across a wide range of business sectors, and for which bounty awards are reported on their website (and a non-disclosed amount of private programs). Previous research has investigated vulnerability trends, response and resolve behaviors, and reward structures of participating organizations. In particular, it was found that a considerable number of organizations exhibit decreasing trends for reported vulnerabilities, yet monetary incentives have a significantly positive correlation with the number of vulnerabilities reported \cite{zhao2015empirical}.