\section{Related work}
\label{sec:related}
Achieving software reliability has concerned engineers for at least four decades \cite{littlewood1973bayesian,adams1984textordfeminineoptimizing,littlewood1989predicting}. Early empirical work on software bug discovery dates back to the time of UNIX systems \cite{miller1990empirical}, and over years, numbers of models for discovering vulnerabilities have been developed (see \cite{yamaguchi2014modeling,zhao2016empirical} for some of the most contemporary approaches to date). However, as early as in 1989, it was recognized the the time to achieve a given level of reliability is inversely proportional to desired frequency level (e.g., to achieve a $10^{-9}$ probability of failure, it takes $10^{9}$ time units) \cite{adams1984textordfeminineoptimizing}. Actually, the random variable $P(T > t) = 1/t$ corresponds to the Zipf's law, which diverges as the random variable sample increases (i.e., no statistical moment is defined) \cite{maillart2008empirical,saichev2009theory}, and thus, it was rightly concluded that there would be software vulnerabilities as long as long enough resources and time could be provided to find them. This problem can also be seen from an entropy maximization perspective, which is good for evolution (e.g., in biology) but detrimental in software engineering \cite{brady1999murphy}. \\

To date, no systematic algorithm approach has been found to get rid of bugs at a speed that would allow following the general pace of software evolution and expansion. Thus human intelligence is still considered as one of the most efficient ways to find bugs, and most importantly to uncover software vulnerabilities. Management techniques and governance approached have been developed to help software developers and security researchers in their review tasks, starting with {\it pair programming} \cite{hulkko2005multiple}. To protect against cyber-criminals, it is also fashionable to hire {\it ethical hackers}, who use the mindset of potential attackers to test the security of computer systems \cite{smith2002ethical,saleem2006ethical,bishop2007penetration}. Inherited from the open source mindset, the full-disclosure policy has been hotly debated as promoting a safer Internet \cite{arora2008optimal}, although in practice it seems that public disclosure has increasingly become a dominant standard to get people and organizations informed as fast as possible about software vulnerabilities.\\

In most of these successful human-driven approaches, there is knowledge-sharing component, may it be between two programmers sitting together in front of a screen, ethical hackers being hired to discover and explore the weaknesses of a computer system, or the broader community being exposed to open source code and publicly disclosed software vulnerabilities. Thus, Eric Raymond's famous quote ``Given enough eyeballs, all bugs shallow" \cite{raymond1999cathedral}, tends to hold, even though in practice things are often slightly more complicated \cite{hafiz2015game}.\\

Recognizing the importance of trading knowledge, the concept of {\it vulnerability markets} has emerged as a way to ensure appropriate incentives for knowledge transfer \cite{}

\clearpage


{\bf bug bounty markets = best of both worlds : (i) large scale testing by (ii) humans. Larger pool of expertise (c.f., collective intelligence)}



\subsection{Vulnerability Markets}

A market-based approach to software evolution \cite{bacon2009market}

A pure vulnerability market is one in which each discrete vulnerability is a unit of trade with a price assigned to it by the buyer, seller, and demand. In such a market, exclusivity of knowledge is a key factor in overall value, thus when a vulnerability becomes public knowledge, it loses its value. Other factors also come into play, such as the affected product's popularity, the vulnerability's security impact, and the exploit's ease and efficacy. Vulnerabilities in this market retain their peak value when very few people know about them; value decreases through events such as vendor notification, information leaks, independent rediscovery, or accidental discovery of the vulnerability due to attack activity in the wild. Because it's difficult to certify and appraise information exclusivity, many buyers contractually obligate vulnerability reporters to exclusivity agreements to ensure that their information is exclusive to the best of their knowledge. Very few buyers are interested in nonexclusive information. \cite{mckinney2007vulnerability}

Without good testing, systems cannot be made secure or robust. Without metrics for the quality and security of system components, no guarantees can be made about the systems they are used to construct. This paper describes how firms can make the testing process faster and more cost effective while simultaneously providing a reliable metric of quality as one of the outputs of the process. This is accomplished via a market for defect reports, in which testers maximize profits by minimizing the cost of finding defects. The power of competition is harnessed to ensure that testers are paid a fair price for the defects they discover, thereby aligning their incentives with those of the firm developing the system. The price to find, demonstrate, and report a defect that is set by the market serves as the measure of quality. \cite{schechter2002buy}

%debate on the efficiency of private intermediaries versus a social planner\cite{kannan2005market,li2007examination}. While market-mechanisms do not reduce the likelihood that a vulnerability will be exploited, we find evidence that markets increase the time to vulnerability exploit and decrease the overall volume of alerts. \cite{ransbotham2008markets}

\subsection{Bounty Programs}

Measuring software security is difficult and inexact; as a result, the
market for secure software has been compared to a ‘market of lemons.’
Schechter has proposed a vulnerability market in which software producers
offer a time-variable reward to free-market testers who identify vulnerabilities.
This vulnerability market can be used to improve testing and
to create a relative metric of product security. This paper argues that
such a market can best be considered as an auction; auction theory is
then used to tune the structure of this ‘bug auction’ for efficiency and to
better defend against attacks. The incentives for the software producer
are also considered, and some fundamental problems with the concept are
articulated. \cite{ozment2004bug}


\subsection{Auction / Markets}

For real world auctions, the importance of attracting a sufficient number
of bidders cannot be overemphasized: the addition of a single bidder can benefit
the auctioneer more than optimizations using reservation prices and entry fees \cite{bulow1996auctions}


``Casting their results in the terms of a monopsonistic action like the bug auction,
they find that average prices are lower with uncertainty than without and that
prices tend to decline over the series of auctions [NPC03]. (The latter trend
may be countered by the generally increasing difficulty of finding each new bug
as the most obvious or common bugs are remediated [BAB99].)"


``they are also dominant in these markets.
Producers that lack the luxury of dominating their markets may be unwilling
to employ the VM in testing for an open-ended period (i.e. until testers stop
claiming the reward)." (ozment)


``Stuart Schechter proposes that firms create a vulnerability market in order
to ascertain the cost to break of their system. A producer (the entity that has
created and is selling the product to be tested) would offer rewards to the first
testers (persons or organizations who identify vulnerabilities in return for payment)
to inform it of new vulnerabilities in its product. If, after time, the reward
is no longer being claimed, the producer can argue that the cost to break for its
product must be greater than the size of the reward [Sch02a][Sch02b][Sch04]."

``The product is not commercially released until the reward for
finding a vulnerability has gone unclaimed for some period of time."

$\rightarrow$ we will question this assertion (and the answer is it depends on the number of people involved in the program).


``Pre-release, the reward R is small when first offered; it then grows over time
until it is claimed. After each new vulnerability is reported and verified, the
reward amount is reset to R0, the minimum reward value. If a vulnerability is
reported more than once, only the first reporter receives the reward." $\rightarrow$ there is no target.

``The continuously
increasing reward scheme maximizes value at the expense of speed:
it trades potential delays in the reporting of vulnerabilities in return for monetary
savings. A tester can choose to report a vulnerability at any time; waiting
longer increases the reward she will receive, but it also increases the probability
that another tester will report the same vulnerability and thus deprive her of
the reward. (The post-release phase may differ and is described below.) If the
bug is genuine and unique, the reward will be reset"

auction? $\rightarrow$ yes but in time and quantity



`The only vulnerabilities a producer will not learn about are those a tester
identifies and then exploits himself (because he values the exploitation of the
vulnerability more highly than the reward), or those vulnerabilities with black
market value greater than the reward." (take into account the risk to trade on the black market)

``testers’ valuations will in part depend upon the amount of
work they put into identifying the bug (their costs)" $\rightarrow$ here, the software company sets the buying price. Accurate pricing reduces uncertainties and attracts security researchers 

\subsection{Empirical Evidence of Bounty Programs}
``Both programs appear economically efficient, comparing
favorably to the cost of hiring full-time security
researchers. The Chrome VRP features low expected payouts
accompanied by high potential payouts, a strategy
that appears to be effective in engaging a broad community
of vulnerability researchers." \cite{finifter2013empirical}

An exploratory study of white hat behaviors in a web vulnerability disclosure program \cite{zhao2014exploratory}


An empirical study of web vulnerability discovery ecosystems \cite{zhao2015empirical}







