\section{Related work}
\label{sec:related}

Software reliability is at the core of cybersecurity, but it has been found that .. \\

{\bf testing:} existing reliability growth models emphasise the Poisson distribution
of individual software bugs, while the empirically observed reliability growth
for large systems is asymptotically slower than this.\cite{brady1999murphy}. In particular, we establish maximisation properties corresponding to Murphy’s law which work to the advantage of a biological species, but to the detriment of software reliability." \cite{brady1999murphy}


An empirical study of the reliability of UNIX utilities \cite{miller1990empirical}

Modeling and discovering vulnerabilities with code property graphs \cite{yamaguchi2014modeling}

%``This paper describes a different approach to software reliability growth modeling which enables long-term predictions. Using relatively common assumptions, it is shown that the average value of the failure rate of the program, after a particular use-time, t, is bounded by N/(e·t), where N is the initial number of faults. This is conservative since it places a worst-case bound on the reliability rather than making a best estimate. The predictions might be relatively insensitive to assumption violations over the longer term. The theory offers the potential for making long-term software reliability growth predictions based solely on prior estimates of the number of residual faults. The predicted bound appears to agree with a wide range of industrial and experimental reliability data. Less pessimistic results can be obtained if additional assumptions are made about the failure rate distribution of faults."\cite{bishop1996conservative}

%``We tackle two problems of interest to the software assurance community.
%Firstly, existing models of software development (such as the waterfall and
%spiral models) are oriented towards one-off software development projects,
%while the growth of mass market computing has led to a world in which
%most software consists of packages which follow an evolutionary development
%model. This leads us to ask whether anything interesting and useful may
%be said about evolutionary development. We answer in the affirmative. Secondly,
%existing reliability growth models emphasise the Poisson distribution
%of individual software bugs, while the empirically observed reliability growth
%for large systems is asymptotically slower than this. We provide a rigorous
%explanation of this phenomenon. Our reliability growth model is inspired by
%statistical thermodynamics, but also applies to biological evolution. It is in
%close agreement with experimental measurements of the fitness of an evolving
%species and the reliability of commercial software products. However,
%it shows that there are significant differences between the evolution of software
%and the evolution of species. In particular, we establish maximisation
%properties corresponding to Murphy’s law which work to the advantage of a
%biological species, but to the detriment of software reliability." 


\subsection{Software bug exhaustion processes \& empirical results}

ethical hackers \cite{smith2002ethical,saleem2006ethical} and penetration testing ({\bf Neither testers nor sponsors should assert that the penetration test has found all possible flaws, or that the failure to find flaws means that the system is secure}. All types of testing can show only the presence of flaws and never the absence of them. The best that testers can say is that the specific flaws they looked for and failed to find aren't present: this can give some idea of the overall security of the system's design and implementation. ) \cite{bishop2007penetration}. Game of detections: how are security vulnerabilities discovered in the wild? \cite{hafiz2015game}

{\bf bug bounty markets = best of both worlds : (i) large scale testing by (ii) humans. Larger pool of expertise (c.f., collective intelligence)}



\subsection{Vulnerability Markets}

A market-based approach to software evolution \cite{bacon2009market}

A pure vulnerability market is one in which each discrete vulnerability is a unit of trade with a price assigned to it by the buyer, seller, and demand. In such a market, exclusivity of knowledge is a key factor in overall value, thus when a vulnerability becomes public knowledge, it loses its value. Other factors also come into play, such as the affected product's popularity, the vulnerability's security impact, and the exploit's ease and efficacy. Vulnerabilities in this market retain their peak value when very few people know about them; value decreases through events such as vendor notification, information leaks, independent rediscovery, or accidental discovery of the vulnerability due to attack activity in the wild. Because it's difficult to certify and appraise information exclusivity, many buyers contractually obligate vulnerability reporters to exclusivity agreements to ensure that their information is exclusive to the best of their knowledge. Very few buyers are interested in nonexclusive information. \cite{mckinney2007vulnerability}

Without good testing, systems cannot be made secure or robust. Without metrics for the quality and security of system components, no guarantees can be made about the systems they are used to construct. This paper describes how firms can make the testing process faster and more cost effective while simultaneously providing a reliable metric of quality as one of the outputs of the process. This is accomplished via a market for defect reports, in which testers maximize profits by minimizing the cost of finding defects. The power of competition is harnessed to ensure that testers are paid a fair price for the defects they discover, thereby aligning their incentives with those of the firm developing the system. The price to find, demonstrate, and report a defect that is set by the market serves as the measure of quality. \cite{schechter2002buy}

%debate on the efficiency of private intermediaries versus a social planner\cite{kannan2005market,li2007examination}. While market-mechanisms do not reduce the likelihood that a vulnerability will be exploited, we find evidence that markets increase the time to vulnerability exploit and decrease the overall volume of alerts. \cite{ransbotham2008markets}

\subsection{Bounty Programs}

Measuring software security is difficult and inexact; as a result, the
market for secure software has been compared to a ‘market of lemons.’
Schechter has proposed a vulnerability market in which software producers
offer a time-variable reward to free-market testers who identify vulnerabilities.
This vulnerability market can be used to improve testing and
to create a relative metric of product security. This paper argues that
such a market can best be considered as an auction; auction theory is
then used to tune the structure of this ‘bug auction’ for efficiency and to
better defend against attacks. The incentives for the software producer
are also considered, and some fundamental problems with the concept are
articulated. \cite{ozment2004bug}


\subsection{Auction / Markets}

For real world auctions, the importance of attracting a sufficient number
of bidders cannot be overemphasized: the addition of a single bidder can benefit
the auctioneer more than optimizations using reservation prices and entry fees \cite{bulow1996auctions}


``Casting their results in the terms of a monopsonistic action like the bug auction,
they find that average prices are lower with uncertainty than without and that
prices tend to decline over the series of auctions [NPC03]. (The latter trend
may be countered by the generally increasing difficulty of finding each new bug
as the most obvious or common bugs are remediated [BAB99].)"


``they are also dominant in these markets.
Producers that lack the luxury of dominating their markets may be unwilling
to employ the VM in testing for an open-ended period (i.e. until testers stop
claiming the reward)." (ozment)


``Stuart Schechter proposes that firms create a vulnerability market in order
to ascertain the cost to break of their system. A producer (the entity that has
created and is selling the product to be tested) would offer rewards to the first
testers (persons or organizations who identify vulnerabilities in return for payment)
to inform it of new vulnerabilities in its product. If, after time, the reward
is no longer being claimed, the producer can argue that the cost to break for its
product must be greater than the size of the reward [Sch02a][Sch02b][Sch04]."

``The product is not commercially released until the reward for
finding a vulnerability has gone unclaimed for some period of time."

$\rightarrow$ we will question this assertion (and the answer is it depends on the number of people involved in the program).


``Pre-release, the reward R is small when first offered; it then grows over time
until it is claimed. After each new vulnerability is reported and verified, the
reward amount is reset to R0, the minimum reward value. If a vulnerability is
reported more than once, only the first reporter receives the reward." $\rightarrow$ there is no target.

``The continuously
increasing reward scheme maximizes value at the expense of speed:
it trades potential delays in the reporting of vulnerabilities in return for monetary
savings. A tester can choose to report a vulnerability at any time; waiting
longer increases the reward she will receive, but it also increases the probability
that another tester will report the same vulnerability and thus deprive her of
the reward. (The post-release phase may differ and is described below.) If the
bug is genuine and unique, the reward will be reset"

auction? $\rightarrow$ yes but in time and quantity



`The only vulnerabilities a producer will not learn about are those a tester
identifies and then exploits himself (because he values the exploitation of the
vulnerability more highly than the reward), or those vulnerabilities with black
market value greater than the reward." (take into account the risk to trade on the black market)

``testers’ valuations will in part depend upon the amount of
work they put into identifying the bug (their costs)" $\rightarrow$ here, the software company sets the buying price. Accurate pricing reduces uncertainties and attracts security researchers 

\subsection{Empirical Evidence of Bounty Programs}
``Both programs appear economically efficient, comparing
favorably to the cost of hiring full-time security
researchers. The Chrome VRP features low expected payouts
accompanied by high potential payouts, a strategy
that appears to be effective in engaging a broad community
of vulnerability researchers." \cite{finifter2013empirical}

An exploratory study of white hat behaviors in a web vulnerability disclosure program \cite{zhao2014exploratory}


An empirical study of web vulnerability discovery ecosystems \cite{zhao2015empirical}







